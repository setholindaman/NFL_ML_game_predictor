{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# NFL Predictions\n",
    "\n",
    "## University of Denver Data Analytics Bootcamp\n",
    "\n",
    "### August 7, 2019\n",
    "\n",
    "**Presenters:**\n",
    "\n",
    "* Tai Johnson\n",
    "* Seth Oliver\n",
    "* Matthew Stewart\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Purpose\n",
    "\n",
    "The purpose of this project was to use machine learning to build a predictor for the outcomes of NFL matchups.  This was a classification problem, where the possible outcomes (classes) of results were Win, Lose, and Draw.\n",
    "\n",
    "We extracted our data from the data sources listed below and cleaned the data using both Microsoft Excel and Python Pandas.  Finally, we built classification models using Logistic Regression, SVM, and Deep Learning; we then analyzed and visualized the results of these models.\n",
    "\n",
    "### Data Sources\n",
    "\n",
    "[NFL Historic Matchups](https://www.kaggle.com/tobycrabtree/nfl-scores-and-betting-data/home#spreadspoke_scores.csv)  \n",
    "[NFL Stadium Info](https://www.kaggle.com/tobycrabtree/nfl-scores-and-betting-data/home#nfl_stadiums.csv)  \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Agenda\n",
    "\n",
    "### -- Data Processing\n",
    "\n",
    "### -- Initial Functions and Correlation Analysis\n",
    "\n",
    "### -- Logistic Regression\n",
    "\n",
    "### -- Support Vector Machine\n",
    "\n",
    "### -- Deep Learning\n",
    "\n",
    "### -- Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# 1.  Data Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Dataset One:  NFL Historic Matchup\n",
    "\n",
    "![alt text](Images/nfl_scores.png \"NFL Historic Matchups\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Dataset Two: NFL Stadiums\n",
    "\n",
    "![alt text](Images/nfl_stadiums.png \"NFL Stadiums\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Combined Datasets\n",
    "\n",
    "### Added stadium information to Dataset One using VLOOKUP\n",
    "\n",
    "![alt text](Images/nfl_datasets_combined.png \"NFL Datasets Combined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Encoded Dataset\n",
    "\n",
    "#### -- Added Game ID\n",
    "#### -- Duplicated Dataset\n",
    "#### -- Sorted By Game ID\n",
    "#### -- One Hot Encoded\n",
    "\n",
    "![alt text](Images/nfl_datasets_encoded.png \"NFL Datasets Encoded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Encoding Breakdown\n",
    "\n",
    "#### -- Team\n",
    "#### -- Home/Away\n",
    "#### -- Favorite to Win/Lose\n",
    "#### -- Stadium Indoors/Outdoors/Retractable\n",
    "#### -- Stadium Neutral True/False\n",
    "#### -- Weather Temperature (Bins of <32, 32-80, >80)\n",
    "#### -- Wind Speed (Bins of <15, >=15)\n",
    "#### -- Win/Lose/Draw\n",
    "  \n",
    "  \n",
    "## Did not encode Point Spread prediction\n",
    "\n",
    "#### *(Win Favorite => negative and Lose Favorite => positive)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Cumulative Win Percentages\n",
    "\n",
    "### -- Sorted by Season > Team > Date\n",
    "### -- Switched to Python to iterrate and calculate cumulative win percentages by Season\n",
    "### -- Exported to .csv and used Excel to calculate opponents' win percentages by Season"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "![alt text](Images/nfl_datasets_pre_win_percent.png \"NFL Datasets Sorted\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "![alt text](Images/pandas_win_percent_calc.png \"Pandas Win Percent Calc\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "![alt text](Images/nfl_dataset_final.png \"Final NFL Dataset\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Vegas Benchmark Success Rate:  66.02%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# 2.  Initial Functions and Correlation Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# Import dependencies\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# Ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Confusion Matrix Visualization Function\n",
    "\n",
    "### -- Confusion matrix useful visualization for classification problem\n",
    "### -- Multiple visualizations => function call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Function for preparing a confusion matrix\n",
    "# This function will be used in the confusion matrix visualizations below\n",
    "# IMPORTANT:  Before calling this function, you should use fig = plt.figure(figsize = (w,h))\n",
    "# IMPORTANT:  After calling this function, you still have to type plt.show().\n",
    "# This is so that you can use multiple subplots in a single figure.\n",
    "\n",
    "def prep_confusion_visual(dataframe, subplot_nums, score, title):\n",
    "    names = dataframe.columns\n",
    "    ax = fig.add_subplot(subplot_nums)\n",
    "    cax = ax.matshow(dataframe, cmap=plt.get_cmap('autumn'))\n",
    "    fig.colorbar(cax)\n",
    "    \n",
    "    ticks = np.arange(0,len(dataframe.columns),1)\n",
    "    ax.set_xticks(ticks)\n",
    "    ax.set_yticks(ticks)\n",
    "    ax.set_xticklabels(dataframe.columns, rotation = 90, fontsize = 10)\n",
    "    ax.set_yticklabels(dataframe.columns, fontsize = 10)\n",
    "\n",
    "    score_formatted = \"{:.2%}\".format(score)\n",
    "    \n",
    "    plt.title(f'''\n",
    "    {title}\n",
    "\n",
    "    Score: {score_formatted}\n",
    "    ''', y=1.12, fontsize = 16, fontweight='bold')\n",
    "    plt.xlabel('Predicted', fontweight='bold', fontsize = 14)\n",
    "    ax.xaxis.set_label_position('top')\n",
    "    plt.ylabel('Actual', fontweight='bold', fontsize = 14)\n",
    "\n",
    "    for i in range(len(dataframe.columns)):\n",
    "        for j in range(len(dataframe.columns)):\n",
    "            text = ax.text(j, i, dataframe.iloc[i, j],\n",
    "                           ha=\"center\", va=\"center\", color=\"black\", fontsize = 14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Read Data/Split into Training and Testing Sets\n",
    "\n",
    "### -- Did not want randomization when splitting into training and testing sets\n",
    "### -- Did not use train_test_split\n",
    "### -- Training Data = Years 2009-2016\n",
    "### -- Testing Data = Years 2017-2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Game ID</th>\n",
       "      <th>schedule_date</th>\n",
       "      <th>schedule_season</th>\n",
       "      <th>schedule_week</th>\n",
       "      <th>schedule_week_clean</th>\n",
       "      <th>schedule_playoff</th>\n",
       "      <th>team</th>\n",
       "      <th>team_id</th>\n",
       "      <th>cumulative_win_percent</th>\n",
       "      <th>cum_win_25</th>\n",
       "      <th>...</th>\n",
       "      <th>weather_wind_mph</th>\n",
       "      <th>wind_below_15</th>\n",
       "      <th>wind_GTE_15</th>\n",
       "      <th>win_lose_draw</th>\n",
       "      <th>stadium</th>\n",
       "      <th>stadium_surface</th>\n",
       "      <th>weather_humidity</th>\n",
       "      <th>weather_detail</th>\n",
       "      <th>vegas_success</th>\n",
       "      <th>vegas_success_rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>9/2/1966</td>\n",
       "      <td>1966</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>Miami Dolphins</td>\n",
       "      <td>MIA</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Orange Bowl</td>\n",
       "      <td>0</td>\n",
       "      <td>71</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.660162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>9/2/1966</td>\n",
       "      <td>1966</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>Oakland Raiders</td>\n",
       "      <td>OAK</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Orange Bowl</td>\n",
       "      <td>0</td>\n",
       "      <td>71</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>9/3/1966</td>\n",
       "      <td>1966</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>Denver Broncos</td>\n",
       "      <td>DEN</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Rice Stadium</td>\n",
       "      <td>Grass</td>\n",
       "      <td>70</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>9/3/1966</td>\n",
       "      <td>1966</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>Houston Oilers</td>\n",
       "      <td>TEN</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Rice Stadium</td>\n",
       "      <td>Grass</td>\n",
       "      <td>70</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>9/4/1966</td>\n",
       "      <td>1966</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>Buffalo Bills</td>\n",
       "      <td>BUF</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Balboa Stadium</td>\n",
       "      <td>Grass</td>\n",
       "      <td>82</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 87 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Game ID schedule_date  schedule_season schedule_week  schedule_week_clean  \\\n",
       "0        1      9/2/1966             1966             1                    1   \n",
       "1        1      9/2/1966             1966             1                    1   \n",
       "2        2      9/3/1966             1966             1                    1   \n",
       "3        2      9/3/1966             1966             1                    1   \n",
       "4        3      9/4/1966             1966             1                    1   \n",
       "\n",
       "   schedule_playoff             team team_id  cumulative_win_percent  \\\n",
       "0             False   Miami Dolphins     MIA                     0.5   \n",
       "1             False  Oakland Raiders     OAK                     0.5   \n",
       "2             False   Denver Broncos     DEN                     0.5   \n",
       "3             False   Houston Oilers     TEN                     0.5   \n",
       "4             False    Buffalo Bills     BUF                     0.5   \n",
       "\n",
       "   cum_win_25         ...          weather_wind_mph  wind_below_15  \\\n",
       "0           0         ...                       6.0              1   \n",
       "1           0         ...                       6.0              1   \n",
       "2           0         ...                       7.0              1   \n",
       "3           0         ...                       7.0              1   \n",
       "4           0         ...                       7.0              1   \n",
       "\n",
       "   wind_GTE_15  win_lose_draw         stadium  stadium_surface  \\\n",
       "0            0              1     Orange Bowl                0   \n",
       "1            0              0     Orange Bowl                0   \n",
       "2            0              1    Rice Stadium            Grass   \n",
       "3            0              0    Rice Stadium            Grass   \n",
       "4            0              1  Balboa Stadium            Grass   \n",
       "\n",
       "   weather_humidity  weather_detail  vegas_success  vegas_success_rate  \n",
       "0                71             NaN            NaN            0.660162  \n",
       "1                71             NaN            NaN                 NaN  \n",
       "2                70             NaN            NaN                 NaN  \n",
       "3                70             NaN            NaN                 NaN  \n",
       "4                82             NaN            NaN                 NaN  \n",
       "\n",
       "[5 rows x 87 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read in dataset\n",
    "games = pd.read_csv('Resources/nfl_data_with_final_win_percentages_plus_opp.csv')\n",
    "games.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Manually split the data into training and testing sets, rather than allowing train_test_split to randomize the split\n",
    "games_train = games[(games['schedule_season'] >= 2009) & (games['schedule_season'] <= 2016)]\n",
    "games_test = games[games['schedule_season'] >= 2017]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Eliminate non-numeric columns for training data\n",
    "games_train_filtered = games_train[[\n",
    "    'cumulative_win_percent',\n",
    "    'opp_win_percent',\n",
    "    'Miami Dolphins',\n",
    "    'Oakland Raiders',\n",
    "#     'Houston Oilers',\n",
    "    'Denver Broncos',\n",
    "    'San Diego Chargers',\n",
    "    'Buffalo Bills',\n",
    "    'Green Bay Packers',\n",
    "#     'Baltimore Colts',\n",
    "    'Atlanta Falcons',\n",
    "#     'Los Angeles Rams',\n",
    "    'Detroit Lions',\n",
    "    'Chicago Bears',\n",
    "    'Pittsburgh Steelers',\n",
    "    'New York Giants',\n",
    "    'San Francisco 49ers',\n",
    "    'Minnesota Vikings',\n",
    "#     'St. Louis Cardinals',\n",
    "    'Philadelphia Eagles',\n",
    "    'Washington Redskins',\n",
    "    'Cleveland Browns',\n",
    "    'New York Jets',\n",
    "    'New England Patriots',\n",
    "    'Kansas City Chiefs',\n",
    "    'Dallas Cowboys',\n",
    "#     'Boston Patriots',\n",
    "    'New Orleans Saints',\n",
    "    'Cincinnati Bengals',\n",
    "    'Tampa Bay Buccaneers',\n",
    "    'Seattle Seahawks',\n",
    "#     'Los Angeles Raiders',\n",
    "    'Indianapolis Colts',\n",
    "#     'Phoenix Cardinals',\n",
    "    'Arizona Cardinals',\n",
    "    'Carolina Panthers',\n",
    "    'St. Louis Rams',\n",
    "    'Jacksonville Jaguars',\n",
    "    'Baltimore Ravens',\n",
    "#     'Tennessee Oilers',\n",
    "    'Tennessee Titans',\n",
    "    'Houston Texans',\n",
    "#     'Los Angeles Chargers',\n",
    "    'Home',\n",
    "    'Away',\n",
    "    'Favorite_to_Win',\n",
    "    'Favorite_to_Lose',\n",
    "    'spread_favorite_clean',\n",
    "    'stadium_indoors',\n",
    "    'stadium_outdoors',\n",
    "    'stadium_retractable',\n",
    "    'stadium_neutral_true',\n",
    "    'stadium_neutral_false',\n",
    "    'temp_below_32',\n",
    "    'temp_32_to_80',\n",
    "    'temp_above_80',\n",
    "    'wind_below_15',\n",
    "    'wind_GTE_15',\n",
    "    'win_lose_draw'    \n",
    "]]\n",
    "games_train_filtered.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Eliminate non-numeric columns for testing data\n",
    "games_test_filtered = games_test[[\n",
    "    'cumulative_win_percent',\n",
    "    'opp_win_percent',\n",
    "    'Miami Dolphins',\n",
    "    'Oakland Raiders',\n",
    "#     'Houston Oilers',\n",
    "    'Denver Broncos',\n",
    "    'San Diego Chargers',\n",
    "    'Buffalo Bills',\n",
    "    'Green Bay Packers',\n",
    "#     'Baltimore Colts',\n",
    "    'Atlanta Falcons',\n",
    "#     'Los Angeles Rams',\n",
    "    'Detroit Lions',\n",
    "    'Chicago Bears',\n",
    "    'Pittsburgh Steelers',\n",
    "    'New York Giants',\n",
    "    'San Francisco 49ers',\n",
    "    'Minnesota Vikings',\n",
    "#     'St. Louis Cardinals',\n",
    "    'Philadelphia Eagles',\n",
    "    'Washington Redskins',\n",
    "    'Cleveland Browns',\n",
    "    'New York Jets',\n",
    "    'New England Patriots',\n",
    "    'Kansas City Chiefs',\n",
    "    'Dallas Cowboys',\n",
    "#     'Boston Patriots',\n",
    "    'New Orleans Saints',\n",
    "    'Cincinnati Bengals',\n",
    "    'Tampa Bay Buccaneers',\n",
    "    'Seattle Seahawks',\n",
    "#     'Los Angeles Raiders',\n",
    "    'Indianapolis Colts',\n",
    "#     'Phoenix Cardinals',\n",
    "    'Arizona Cardinals',\n",
    "    'Carolina Panthers',\n",
    "    'St. Louis Rams',\n",
    "    'Jacksonville Jaguars',\n",
    "    'Baltimore Ravens',\n",
    "#     'Tennessee Oilers',\n",
    "    'Tennessee Titans',\n",
    "    'Houston Texans',\n",
    "#     'Los Angeles Chargers',\n",
    "    'Home',\n",
    "    'Away',\n",
    "    'Favorite_to_Win',\n",
    "    'Favorite_to_Lose',\n",
    "    'spread_favorite_clean',\n",
    "    'stadium_indoors',\n",
    "    'stadium_outdoors',\n",
    "    'stadium_retractable',\n",
    "    'stadium_neutral_true',\n",
    "    'stadium_neutral_false',\n",
    "    'temp_below_32',\n",
    "    'temp_32_to_80',\n",
    "    'temp_above_80',\n",
    "    'wind_below_15',\n",
    "    'wind_GTE_15',\n",
    "    'win_lose_draw'    \n",
    "]]\n",
    "games_test_filtered.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Drop rows with NaN in training data\n",
    "games_train_filtered.dropna(inplace=True)\n",
    "games_train_filtered.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Drop rows with NaN in testing data\n",
    "games_test_filtered.dropna(inplace=True)\n",
    "games_test_filtered.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Correlation Matrix\n",
    "\n",
    "### -- Difficult to glean useful information from this visualization\n",
    "### -- Data is almost entirely one hot encoded (0s and 1s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Create correlation matrix to analyze correlations among pairs of features\n",
    "names = games_train_filtered.columns[:-1]\n",
    "correlations = games_train_filtered.corr()\n",
    "fig = plt.figure(figsize = [25,20])\n",
    "ax = fig.add_subplot(111)\n",
    "cax = ax.matshow(correlations, vmin=-1, vmax=1)\n",
    "fig.colorbar(cax)\n",
    "ticks = np.arange(0,len(correlations.columns),1)\n",
    "ax.set_xticks(ticks)\n",
    "ax.set_yticks(ticks)\n",
    "ax.set_xticklabels(correlations.columns, rotation = 90)\n",
    "ax.set_yticklabels(correlations.columns)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Zoom in on columns that have more interesting activity from above visaulization\n",
    "zoom_in_on_columns = ['Away', 'Home', 'Favorite_to_Win']\n",
    "simpler_correlations = correlations.loc[zoom_in_on_columns, zoom_in_on_columns]\n",
    "\n",
    "fig = plt.figure(figsize = [25,20])\n",
    "ax = fig.add_subplot(111)\n",
    "cax = ax.matshow(simpler_correlations, vmin=-1, vmax=1)\n",
    "fig.colorbar(cax)\n",
    "ticks = np.arange(0,len(simpler_correlations.columns),1)\n",
    "ax.set_xticks(ticks)\n",
    "ax.set_yticks(ticks)\n",
    "ax.set_xticklabels(simpler_correlations.columns, rotation = 90, fontsize = 14)\n",
    "ax.set_yticklabels(simpler_correlations.columns, fontsize = 14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Final Splitting of Data into X and y\n",
    "\n",
    "### -- Have training and test dataframes\n",
    "### -- Not yet split into an X or a y\n",
    "### -- Finish by scaling data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# win_lose_draw is the y column\n",
    "X_train = games_train_filtered.drop(\"win_lose_draw\", axis=1)\n",
    "y_train = games_train_filtered[\"win_lose_draw\"].values.reshape(-1, 1)\n",
    "print(X_train.shape, y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# win_lose_draw is the y column\n",
    "X_test = games_test_filtered.drop(\"win_lose_draw\", axis=1)\n",
    "y_test = games_test_filtered[\"win_lose_draw\"].values.reshape(-1, 1)\n",
    "print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# scale X data\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "\n",
    "X_scaler = MinMaxScaler().fit(X_train)\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# 3. Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## -- Typically used for binary dependent variable (0 or 1)\n",
    "\n",
    "## -- With more than two outcomes, becomes multinomial logistic regression\n",
    "\n",
    "## -- Our possible outcomes are 0, 1, or 2 (win, lose, or draw)\n",
    "\n",
    "## -- Code in python works the same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Create a logistic regression model\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "classifier = LogisticRegression()\n",
    "classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Fit the data\n",
    "classifier.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Score the data\n",
    "logistic_train_score = classifier.score(X_train_scaled, y_train)\n",
    "logistic_test_score = classifier.score(X_test_scaled, y_test)\n",
    "print(f'Logistic Regression score on train data is {logistic_train_score}')\n",
    "print(f'Logistic Regression score on test data is {logistic_test_score}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Detour - To Use the Vegas Data or Not?\n",
    "\n",
    "### -- With Vegas data included in features, score is 67%\n",
    "\n",
    "### -- Problematic to use Vegas data?\n",
    "\n",
    "### -- What is the score when excluding the Vegas data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Re-do training data, this time with no Vegas columns\n",
    "X_train_no_vegas = X_train.drop(['Favorite_to_Win', 'Favorite_to_Lose', 'spread_favorite_clean'], axis=1)\n",
    "X_train_no_vegas.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Re-do testing data, this time with no Vegas columns\n",
    "X_test_no_vegas = X_test.drop(['Favorite_to_Win', 'Favorite_to_Lose', 'spread_favorite_clean'], axis=1)\n",
    "X_test_no_vegas.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Scale the data\n",
    "X_scaler_no_vegas = MinMaxScaler().fit(X_train_no_vegas)\n",
    "X_train_no_vegas_scaled = X_scaler_no_vegas.transform(X_train_no_vegas)\n",
    "X_test_no_vegas_scaled = X_scaler_no_vegas.transform(X_test_no_vegas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Re-do logistic regression with non-vegas data\n",
    "classifier_no_vegas = LogisticRegression()\n",
    "classifier_no_vegas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Fit\n",
    "classifier_no_vegas.fit(X_train_no_vegas_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Score\n",
    "print(f'Logistic Regression score on train data (no Vegas) is {classifier_no_vegas.score(X_train_no_vegas_scaled, y_train)}')\n",
    "print(f'Logistic Regression score on test data (no Vegas) is {classifier_no_vegas.score(X_test_no_vegas_scaled, y_test)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Vegas Data or Not?\n",
    "\n",
    "#### -- With Vegas data, score is 67%\n",
    "\n",
    "#### -- No Vegas data, score is 61%\n",
    "\n",
    "#### -- Vegas data probably includes player-specific information that we do not have access to\n",
    "\n",
    "#### -- Vegas data is available prior to each week's games\n",
    "\n",
    "## Conclusion:  Use Vegas Data\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Logistic Regression Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# generate accuracy dataframe\n",
    "logistic_predictions = classifier.predict(X_test_scaled)\n",
    "logistic_accuracy = pd.DataFrame({\"Prediction\": list(logistic_predictions), \"Actual\": y_test.ravel()}).reset_index(drop=True)\n",
    "logistic_accuracy['Correct'] = logistic_accuracy.Prediction == logistic_accuracy.Actual\n",
    "logistic_accuracy.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Create confusion matrix dataframe\n",
    "logistic_y_actu = pd.Series(y_test.ravel(), name='Actual')\n",
    "logistic_y_pred = pd.Series(logistic_predictions, name='Predicted')\n",
    "\n",
    "logistic_df_confusion = pd.crosstab(logistic_y_actu, logistic_y_pred)\n",
    "logistic_df_confusion.columns = ['Win', 'Lose']\n",
    "logistic_df_confusion.rename(index={\n",
    "    logistic_df_confusion.index[0]: 'Win',\n",
    "    logistic_df_confusion.index[1]: 'Lose',\n",
    "    logistic_df_confusion.index[2]: 'Draw'\n",
    "}, inplace=True)\n",
    "logistic_df_confusion['Draw'] = 0\n",
    "logistic_df_confusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Function call to generate Logistic Regression confusion visualization\n",
    "fig = plt.figure(figsize = (10,8))\n",
    "prep_confusion_visual(logistic_df_confusion, 111, logistic_test_score, 'Logistic Regression')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# 4.  Support Vector Machine (SVM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## -- Can be used for both regression or classification (usually for classification)\n",
    "\n",
    "## -- Goal is to find hyperplane that maximizes distance between classes\n",
    "\n",
    "![alt text](Images/svm_image.png \"SVM Image\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Create and train model\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "svm_model = SVC(kernel='linear')\n",
    "svm_model.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# Score model\n",
    "\n",
    "svm_train_score = svm_model.score(X_train_scaled, y_train)\n",
    "svm_test_score = svm_model.score(X_test_scaled, y_test)\n",
    "\n",
    "print(f'SVM score on train data is {svm_train_score}')\n",
    "print(f'SVM score on test data is {svm_test_score}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# Grid search\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "param_grid = {\n",
    "    'C': [1, 5, 10],\n",
    "    'gamma': [0.0001, 0.001, 0.01]\n",
    "}\n",
    "grid = GridSearchCV(svm_model, param_grid, verbose = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# Grid fit\n",
    "\n",
    "grid.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# Grid results\n",
    "\n",
    "print(grid.best_params_)\n",
    "print(grid.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## SVM Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# accuracy dataframe\n",
    "\n",
    "svm_predictions = svm_model.predict(X_test_scaled)\n",
    "svm_accuracy = pd.DataFrame({\"Prediction\": list(svm_predictions), \"Actual\": y_test.ravel()}).reset_index(drop=True)\n",
    "svm_accuracy['Correct'] = svm_accuracy.Prediction == svm_accuracy.Actual\n",
    "svm_accuracy.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Create confusion matrix dataframe\n",
    "svm_y_actu = pd.Series(y_test.ravel(), name='Actual')\n",
    "svm_y_pred = pd.Series(svm_predictions, name='Predicted')\n",
    "\n",
    "svm_df_confusion = pd.crosstab(svm_y_actu, svm_y_pred)\n",
    "svm_df_confusion.columns = ['Win', 'Lose']\n",
    "svm_df_confusion.rename(index={\n",
    "    svm_df_confusion.index[0]: 'Win',\n",
    "    svm_df_confusion.index[1]: 'Lose',\n",
    "    svm_df_confusion.index[2]: 'Draw'\n",
    "}, inplace=True)\n",
    "svm_df_confusion['Draw'] = 0\n",
    "svm_df_confusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Function call to generate SVM confusion matrix visualization\n",
    "fig = plt.figure(figsize = (10,8))\n",
    "prep_confusion_visual(svm_df_confusion, 111, svm_test_score, 'SVM')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# 5. Deep Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## -- Multiple layers of algorithms working to interpret data\n",
    "\n",
    "## -- Artificial neural networks\n",
    "\n",
    "![alt text](Images/deep_learning_image.png \"Deep Learning Image\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Create and summarize model\n",
    "# Use 147 nodes in each hidden unit (3x 49 columns of X data)\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(y_train)\n",
    "encoded_y_train = label_encoder.transform(y_train)\n",
    "encoded_y_test = label_encoder.transform(y_test)\n",
    "\n",
    "y_train_categorical = to_categorical(encoded_y_train)\n",
    "y_test_categorical = to_categorical(encoded_y_test)\n",
    "\n",
    "deep_model = Sequential()\n",
    "deep_model.add(Dense(units=147, activation='relu', input_dim=len(X_train.columns)))\n",
    "deep_model.add(Dense(units=147, activation='relu'))\n",
    "deep_model.add(Dense(units=3, activation='softmax'))\n",
    "\n",
    "deep_model.compile(optimizer='adam',\n",
    "                    loss='categorical_crossentropy',\n",
    "                    metrics=['accuracy'])\n",
    "\n",
    "deep_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# label_encoder = LabelEncoder()\n",
    "# label_encoder.fit(y_train)\n",
    "# encoded_y_train = label_encoder.transform(y_train)\n",
    "# encoded_y_test = label_encoder.transform(y_test)\n",
    "\n",
    "# y_train_categorical = to_categorical(encoded_y_train)\n",
    "# y_test_categorical = to_categorical(encoded_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Fit\n",
    "\n",
    "deep_model.fit(\n",
    "    X_train_scaled,\n",
    "    y_train_categorical,\n",
    "    epochs=60,\n",
    "    shuffle=True,\n",
    "    verbose=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# Score\n",
    "\n",
    "deep_model_loss, deep_model_accuracy = deep_model.evaluate(\n",
    "    X_test_scaled, y_test_categorical, verbose = 2)\n",
    "\n",
    "print(\n",
    "    f'''\n",
    "    Deep Neural Network\n",
    "    Loss: {deep_model_loss}\n",
    "    Accuracy: {deep_model_accuracy}\n",
    "    '''\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Deep Learning Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Create accuracy dataframe\n",
    "encoded_prediction = deep_model.predict_classes(X_test_scaled)\n",
    "deep_predictions = label_encoder.inverse_transform(encoded_prediction)\n",
    "\n",
    "deep_accuracy = pd.DataFrame({\"Prediction\": list(deep_predictions), \"Actual\": y_test.ravel()}).reset_index(drop=True)\n",
    "deep_accuracy['Correct'] = deep_accuracy.Prediction == deep_accuracy.Actual\n",
    "deep_accuracy.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "deep_y_actu = pd.Series(y_test.ravel(), name='Actual')\n",
    "deep_y_pred = pd.Series(deep_predictions, name='Predicted')\n",
    "deep_df_confusion = pd.crosstab(deep_y_actu, deep_y_pred)\n",
    "\n",
    "deep_df_confusion.columns = ['Win', 'Lose', 'Draw']\n",
    "\n",
    "deep_df_confusion.rename(index={\n",
    "    deep_df_confusion.index[0]: 'Win',\n",
    "    deep_df_confusion.index[1]: 'Lose',\n",
    "    deep_df_confusion.index[2]: 'Draw'\n",
    "}, inplace=True)\n",
    "\n",
    "deep_df_confusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize = (10,8))\n",
    "prep_confusion_visual(deep_df_confusion, 111, deep_model_accuracy, 'Deep Learning')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# 6. Conclusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize = (18,8))\n",
    "prep_confusion_visual(logistic_df_confusion, 131, logistic_test_score, 'Logistic Regression')\n",
    "prep_confusion_visual(svm_df_confusion, 132, svm_test_score, 'SVM')\n",
    "prep_confusion_visual(deep_df_confusion, 133, deep_model_accuracy, 'Deep Learning')\n",
    "plt.subplots_adjust(right=1.1, top=0.8)\n",
    "plt.suptitle('Vegas Benchmark: 66.02%', fontweight = 'bold', fontsize = 22)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Questions"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
